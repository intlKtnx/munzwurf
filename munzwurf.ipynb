{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_cache = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Search for all h5 files\n",
    "        p = Path(file_path)\n",
    "        files = p.glob('*.h5')\n",
    "        for h5dataset_fp in files:\n",
    "            with h5py.File(h5dataset_fp.resolve()) as h5_file:\n",
    "                # Walk through all groups, extracting datasets\n",
    "                for gname, group in h5_file.items():\n",
    "                    if gname == 'oneCent':\n",
    "                        label = 1\n",
    "                    elif gname == 'twoCent':\n",
    "                        label = 2\n",
    "                    elif gname == 'fiveCent':\n",
    "                        label = 5\n",
    "                    elif gname == 'twentyCent':\n",
    "                        label = 20\n",
    "                    elif gname == 'fiftyCent':\n",
    "                        label = 50\n",
    "                    elif gname == 'oneEuro':\n",
    "                        label = 100\n",
    "                    elif gname == 'twoEuro':\n",
    "                        label = 200\n",
    "                    for dname, ds in group.items():\n",
    "                        self.data_cache.append([label, np.array(ds[:760000], dtype=np.float32)])\n",
    "                        #self.data_cache.append([label, torch.tensor((1, ds[:760000]))])\n",
    "                        \n",
    "            print(self.data_cache[0][1])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_cache[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -64. -288. -256. ...   32. -416. -192.]\n"
     ]
    }
   ],
   "source": [
    "file_dir = \"/home/marcus/Documents/munzwurf/data_normalized\"\n",
    "labels_dir = \"/home/marcus/Documents/munzwurf/data/labels.csv\"\n",
    "\n",
    "customData = CustomDataset(\"/home/marcus/PycharmProjects/pythonProject/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, array([ 224.,   64.,  -96., ..., -576., -160.,   96.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(customData)\n",
    "customData[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.array(np.floor(np.random.rand(100) * 1000), dtype=int)\n",
    "#tested a bunch of random indices to get a balanced representation of labels\n",
    "tested_indices = [ 75, 296, 705, 917, 596, 117, 987, 681, 746, 189, 868, 661, 752, 462, 362, 322,  50,  90,\n",
    " 526,  53, 15, 403, 881, 226, 428, 453,  80, 312, 486, 690, 842, 959, 247, 224, 748, 772,\n",
    " 620, 617, 108,  96, 212, 649, 866, 707, 956, 772, 234, 339, 166, 954, 602, 935, 707, 717,\n",
    "  14, 672, 891, 415, 199, 511,   2, 998, 628, 651,  47, 115, 966,  29,   5, 240, 371,  85,\n",
    "  18, 997,  68, 170, 325, 807, 378, 566, 763, 121,   3, 442, 674, 938, 393, 763, 755, 336,\n",
    " 419, 408, 104, 923, 580, 530, 859, 371, 957, 535]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array([], dtype=int)\n",
    "test_labels = [i[0] for i in customData[::20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(customData, tested_indices)\n",
    "test_data = Subset(CustomDataset, np.arange(800, len(customData)))\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=False, num_workers=4)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=4, shuffle=True, pin_memory=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count = []\n",
    "for i in [1,2,5,20,50,100,200]:\n",
    "    label_count.append(np.count_nonzero(test_labels == i))\n",
    "\n",
    "plt.bar(range(7), label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 2, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv1d(2, 4, kernel_size=3, padding=1) \n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=3, padding=1) \n",
    "        self.conv4 = nn.Conv1d(8, 16, kernel_size=3, padding=1) \n",
    "        self.conv5 = nn.Conv1d(16, 32, kernel_size=3, padding=1) \n",
    "      \n",
    "        self.fc1   = nn.Linear(101248, 7)  #262500\n",
    "     \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv3(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv4(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv5(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1) \n",
    "        print(x.shape)\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "        \"\"\"\n",
    "        Size after each layer\n",
    "        torch.Size([64, 1, 262500])\n",
    "        torch.Size([64, 1, 131250])\n",
    "        torch.Size([64, 1, 65625])\n",
    "        torch.Size([64, 1, 32812])\n",
    "        torch.Size([64, 1, 16406])\n",
    "        \"\"\"\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv1d(1, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(2, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv4): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv5): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=101248, out_features=7, bias=True)\n",
      ")\n",
      "710851\n"
     ]
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4435/1847332878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    j = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        print(type(data[1]))\n",
    "        inputs = torch.tensor([1, data[1]])\n",
    "        labels = data[0]\n",
    "        print(\"inputs\", inputs[0], \"labels\", labels[1])\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #loss_array.append(loss.item())\n",
    "        #loss_plot = plt.plot(range(len(loss_array)), loss_array)\n",
    "        #plt.show()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(loss)\n",
    "        if i % 5 == 4:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            print(outputs, labels)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
