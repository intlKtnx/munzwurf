{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, labels_file, file_dir, transform=None):\n",
    "        self.labels = pd.read_csv(labels_file)\n",
    "        self.labels_array = np.array(torch.tensor(self.labels.iloc[:, 1]))\n",
    "        self.file_dir = file_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.file_dir, self.labels.iloc[idx,0])\n",
    "        file = np.genfromtxt (file_path,dtype=int, delimiter=\",\")\n",
    "        file = np.pad(file, (0, 769024 - len(file)))\n",
    "        file = torch.from_numpy(file).float().reshape( 1, -1)\n",
    "        label = self.labels.iloc[idx,1]\n",
    "        sample = {\"file\" : file, \"label\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/home/marcus/Documents/munzwurf/data\"\n",
    "\n",
    "customData = CustomDataset(os.path.join(file_dir, \"labels.csv\"), file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[449 708  96 748 164 518  43 658 959 339 430 377 827 218 135 441 584  35\n",
      " 925 312 474 804 623 121 926 115 847 212 449 116 639 726 410 932  41 317\n",
      " 517 861 296 279 100 432 565 325 851 544 162 900 499 799 551 863 467 233\n",
      " 364 739 229 203 899  66 498 898 538 852 537  67 723  81 990 359 305 855\n",
      " 993 992 898   1 418 100 671 506 666 278 447 775 570 805 568 873 134  24\n",
      " 385 992 721 156 116 429 984 913 232 139]\n"
     ]
    }
   ],
   "source": [
    "random_indices = np.array(np.floor(np.random.rand(100) * 1000), dtype=int)\n",
    "print(random_indices)\n",
    "#tested a bunch of random indices to get a balanced representation of labels\n",
    "tested_indices = [ 75, 296, 705, 917, 596, 117, 987, 681, 746, 189, 868, 661, 752, 462, 362, 322,  50,  90,\n",
    " 526,  53, 15, 403, 881, 226, 428, 453,  80, 312, 486, 690, 842, 959, 247, 224, 748, 772,\n",
    " 620, 617, 108,  96, 212, 649, 866, 707, 956, 772, 234, 339, 166, 954, 602, 935, 707, 717,\n",
    "  14, 672, 891, 415, 199, 511,   2, 998, 628, 651,  47, 115, 966,  29,   5, 240, 371,  85,\n",
    "  18, 997,  68, 170, 325, 807, 378, 566, 763, 121,   3, 442, 674, 938, 393, 763, 755, 336,\n",
    " 419, 408, 104, 923, 580, 530, 859, 371, 957, 535]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 3 5 5 4 1 3 6 5 1 5 6 0 6 0 3 2 3 4 5 1 3 2 5 3 3 2 6 1 1 2 2 4 6 0 5\n",
      " 1 5 1 1 3 2 5 4 0 1 5 3 6 4 4 5 5 4 0 1 3 6 6 3 0 0 3 1 2 0 6 6 3 5 1 2 6\n",
      " 0 2 2 6 4 3 2 4 0 4 6 0 6 2 0 0 1 0 4 5 3 2 6 5 4 0]\n"
     ]
    }
   ],
   "source": [
    "test_labels = np.array([], dtype=int)\n",
    "for i in range(len(random_indices)):\n",
    "    test_labels = np.append(test_labels, customData.labels_array[tested_indices[i]])\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count = []\n",
    "for i in range(7):\n",
    "    label_count.append(np.count_nonzero(test_labels == i))\n",
    "\n",
    "plt.bar(range(7), label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(customData, tested_indices)\n",
    "test_data = Subset(CustomDataset, np.arange(800, len(customData)))\n",
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, pin_memory=False, num_workers=4)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=4, shuffle=True, pin_memory=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 1, kernel_size=3) \n",
    "        self.conv2 = nn.Conv1d(1, 1, kernel_size=3) \n",
    "        self.conv3 = nn.Conv1d(1, 1, kernel_size=3) \n",
    "        self.conv4 = nn.Conv1d(1, 1, kernel_size=3) \n",
    "        self.conv5 = nn.Conv1d(1, 1, kernel_size=3) \n",
    "      \n",
    "        self.fc1   = nn.Linear(24030, 7)\n",
    "     \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)),2)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)),2)\n",
    "        x = F.max_pool1d(F.relu(self.conv3(x)),2)\n",
    "        x = F.max_pool1d(F.relu(self.conv4(x)),2)\n",
    "        x = F.max_pool1d(F.relu(self.conv5(x)),2)\n",
    "\n",
    "        x = torch.flatten(x, 1) \n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(x)\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
      "  (conv3): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
      "  (conv4): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
      "  (conv5): Conv1d(1, 1, kernel_size=(3,), stride=(1,))\n",
      "  (fc1): Linear(in_features=24030, out_features=7, bias=True)\n",
      "  (fc2): Linear(in_features=7, out_features=7, bias=True)\n",
      ")\n",
      "168293\n"
     ]
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 3, 3, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 4, 5, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 6, 5, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 2, 0, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 5, 1, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 6, 0, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 2, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 3, 0, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 1, 6, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 3, 5, 1], device='cuda:0')\n",
      "[1,    10] loss: 1.937\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 5, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 1, 6, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 2, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 2, 4, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 2, 6, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1108]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 6, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 0, 5, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 1, 5, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 2, 6, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 1, 6, 6], device='cuda:0')\n",
      "[1,    20] loss: 1.958\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 3, 1, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 6, 1, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 2, 5, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 4, 3, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 1, 1, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 3, 0, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 1, 1, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 3, 1, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 1, 4, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 2, 3, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 6, 5, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 1, 0, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 5, 0, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 5, 3, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 4, 6, 0], device='cuda:0')\n",
      "[2,    10] loss: 1.954\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 3, 0, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 3, 3, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 1, 2, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 3, 0, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 5, 6, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 3, 0, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 3, 2, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 2, 6, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 6, 4, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 3, 1, 5], device='cuda:0')\n",
      "[2,    20] loss: 1.941\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 4, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 6, 6, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 4, 4, 6], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 6, 1, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1898, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 3, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 0, 0, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 5, 2, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 3, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 4, 5, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 3, 6, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 1, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 5, 4, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 3, 6, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 5, 4, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 2, 4, 0], device='cuda:0')\n",
      "[3,    10] loss: 1.942\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 2, 2, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 2, 4, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 1, 3, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 2, 0, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 6, 3, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 2, 3, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 6, 3, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 5, 5, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 5, 0, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 1, 6, 0], device='cuda:0')\n",
      "[3,    20] loss: 1.949\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 6, 1, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 0, 3, 5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 6, 0, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 6, 2, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 6, 4, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 1, 6, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 5, 0, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 5, 5, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 1, 3, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 2, 4, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 6, 5, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 5, 6, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 0, 5, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 6, 4, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 2, 3, 5], device='cuda:0')\n",
      "[4,    10] loss: 1.953\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 0, 6, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 4, 5, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 5, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 0, 3, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 4, 5, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 2, 6, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 3, 1, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 6, 0, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 4, 2, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 0, 4, 0], device='cuda:0')\n",
      "[4,    20] loss: 1.945\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 2, 1, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 2, 6, 5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 4, 4, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 5, 4, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 5, 4, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 3, 5, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 4, 4], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 6, 2, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 4, 3, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 3, 2, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 3, 0, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 5, 6, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 2, 6, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 5, 6, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 0, 1, 0], device='cuda:0')\n",
      "[5,    10] loss: 1.950\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 0, 6, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 0, 2, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 1, 5, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 2, 6, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 0, 5, 0], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 5, 3, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 6, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 1, 0, 1], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 1, 3, 4], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 5, 5, 5], device='cuda:0')\n",
      "[5,    20] loss: 1.953\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 4, 4, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 5, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 2, 2, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 0, 0, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 3, 4, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 4, 5, 0], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 0, 5, 0], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 1, 5, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 6, 1, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([1, 3, 1, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 2, 1, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 4, 3, 3], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 2, 1, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 3, 2, 2], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 2, 1, 0], device='cuda:0')\n",
      "[6,    10] loss: 1.949\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 0, 3, 6], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 6, 0, 4], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 1, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 5, 6], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 1, 4, 1], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 4, 6, 0], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 6, 6, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 4, 5, 5], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 6, 0, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 4, 6, 5], device='cuda:0')\n",
      "[6,    20] loss: 1.951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([6, 2, 4, 3], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 4, 5, 5], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 5, 4, 1], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 3, 0, 6], device='cuda:0')\n",
      "tensor([[0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1349, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 2, 0, 2], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([0, 4, 2, 1], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 3, 1, 1], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([4, 0, 1, 4], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 4, 5, 6], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([2, 0, 3, 2], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1897, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([5, 0, 3, 5], device='cuda:0')\n",
      "tensor([[0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109],\n",
      "        [0.1350, 0.1157, 0.1356, 0.1960, 0.1896, 0.1172, 0.1109]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([3, 4, 3, 6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[\"file\"]\n",
    "        labels = data[\"label\"]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(outputs, labels)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
