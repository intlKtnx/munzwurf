{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from torch.utils import data\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_cache = []\n",
    "        self.transform = transform\n",
    "        self.label_count = [0,0,0,0,0,0,0]\n",
    "        # Search for all h5 files\n",
    "        p = Path(file_path)\n",
    "        files = p.glob('coinData_normalized')\n",
    "        for h5dataset_fp in files:\n",
    "            print(h5dataset_fp)\n",
    "            with h5py.File(h5dataset_fp.resolve()) as h5_file:\n",
    "                # Walk through all groups, extracting datasets\n",
    "                for gname, group in h5_file.items():\n",
    "                    if gname == 'oneCent':\n",
    "                        label = 0\n",
    "                    elif gname == 'twoCent':\n",
    "                        label = 1\n",
    "                    elif gname == 'fiveCent':\n",
    "                        label = 2\n",
    "                    elif gname == 'twentyCent':\n",
    "                        label = 3\n",
    "                    elif gname == 'fiftyCent':\n",
    "                        label = 4\n",
    "                    elif gname == 'oneEuro':\n",
    "                        label = 5\n",
    "                    elif gname == 'twoEuro':\n",
    "                        label = 6\n",
    "                    for dname, ds in tqdm(group.items()):\n",
    "                        arr = np.pad(np.array(ds, dtype=np.float32), max(int(np.ceil((500000 - len(ds))/2)), 0))\n",
    "                        self.data_cache.append([label, torch.tensor(arr[:500000]).unsqueeze(0)])\n",
    "                        #self.data_cache.append([label, torch.tensor((1, ds[:760000]))])\n",
    "                        \n",
    "            print(self.data_cache[0][1].size())\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_cache[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marcus/Dokumente/munzwurf/coinData_normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 130/130 [00:00<00:00, 281.64it/s]\n",
      "100%|████████████████████████████████████████| 130/130 [00:00<00:00, 281.96it/s]\n",
      "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 290.87it/s]\n",
      "100%|████████████████████████████████████████| 180/180 [00:00<00:00, 316.26it/s]\n",
      "100%|████████████████████████████████████████| 137/137 [00:00<00:00, 314.83it/s]\n",
      "100%|████████████████████████████████████████| 170/170 [00:00<00:00, 350.43it/s]\n",
      "100%|████████████████████████████████████████| 196/196 [00:00<00:00, 297.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "customData = CustomDataset(\"/home/marcus/Dokumente/munzwurf/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "moved_arr = [x - 0.5 for x in customData[100][1][0]]\n",
    "moved_arr = np.array(moved_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 500000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = librosa.effects.trim(moved_arr, top_db=45)\n",
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(customData[300][1][0])\n",
    "plt.ylabel(customData[300][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.array(np.floor(np.random.rand(100) * 1000), dtype=int)\n",
    "#tested a bunch of random indices to get a balanced representation of labels\n",
    "tested_indices = [ 75, 296, 705, 917, 596, 117, 987, 681, 746, 189, 868, 661, 752, 462, 362, 322,  50,  90,\n",
    " 526,  53, 15, 403, 881, 226, 428, 453,  80, 312, 486, 690, 842, 959, 247, 224, 748, 772,\n",
    " 620, 617, 108,  96, 212, 649, 866, 707, 956, 772, 234, 339, 166, 954, 602, 935, 707, 717,\n",
    "  14, 672, 891, 415, 199, 511,   2, 998, 628, 651,  47, 115, 966,  29,   5, 240, 371,  85,\n",
    "  18, 997,  68, 170, 325, 807, 378, 566, 763, 121,   3, 442, 674, 938, 393, 763, 755, 336,\n",
    " 419, 408, 104, 923, 580, 530, 859, 371, 957, 535]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_number = [0,0,0,0,0,0,0]\n",
    "test_number = [0,0,0,0,0,0,0]\n",
    "train_data_idx = []\n",
    "test_data_idx = []\n",
    "for i in range(len(customData)):\n",
    "    if train_number[customData[i][0]] < 100:\n",
    "        train_data_idx.append(i)\n",
    "        train_number[customData[i][0]] += 1\n",
    "    elif test_number[customData[i][0]] < 25:\n",
    "        test_data_idx.append(i)\n",
    "        test_number[customData[i][0]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array([i[0] for i in customData], dtype = int)\n",
    "train_labels = np.array([customData[i][0] for i in train_data_idx], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(customData, train_data_idx)\n",
    "test_data = Subset(customData, test_data_idx)\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=False, num_workers=4)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=32, shuffle=True, pin_memory=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count = []\n",
    "for i in range(7):\n",
    "    label_count.append(np.count_nonzero(train_labels == i))\n",
    "\n",
    "plt.bar(range(7), label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 2, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv1d(2, 4, kernel_size=3, padding=1) \n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=3, padding=1) \n",
    "        #self.conv4 = nn.Conv1d(8, 16, kernel_size=3, padding=1) \n",
    "        #self.conv5 = nn.Conv1d(16, 32, kernel_size=3, padding=1) \n",
    "        \n",
    "        self.fc1   = nn.Linear(32000, 7) \n",
    "     \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)),5)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)),5)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv3(x)),5)\n",
    "        #print(x.shape)\n",
    "        #x = F.max_pool1d(F.relu(self.conv4(x)),3)\n",
    "        #print(x.shape)\n",
    "        #x = F.max_pool1d(F.relu(self.conv5(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1) \n",
    "        #print(x.shape)\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv1d(1, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(2, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=32000, out_features=7, bias=True)\n",
      ")\n",
      "224147\n"
     ]
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer, criterion, model):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    j = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [labels, inputs]\n",
    "        \n",
    "        inputs = data[1]\n",
    "        labels = data[0]        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10), end=\" \")\n",
    "            running_loss = 0.0\n",
    "            if ((epoch+1) % 50) == 0:\n",
    "                print(outputs[1:10], labels[1:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(dataloader, optimizer, criterion, model):   \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for labels, inputs in dataloader:\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.983 Test Error: Accuracy: 14.3%, Avg loss: 1.962510 \n",
      "[2,    10] loss: 1.993 Test Error: Accuracy: 14.3%, Avg loss: 2.010701 \n",
      "[3,    10] loss: 1.972 Test Error: Accuracy: 21.7%, Avg loss: 1.949938 \n",
      "[4,    10] loss: 1.962 Test Error: Accuracy: 13.1%, Avg loss: 1.960445 \n",
      "[5,    10] loss: 1.962 Test Error: Accuracy: 20.6%, Avg loss: 1.945697 \n",
      "[6,    10] loss: 1.941 Test Error: Accuracy: 20.0%, Avg loss: 1.946150 \n",
      "[7,    10] loss: 1.942 Test Error: Accuracy: 14.3%, Avg loss: 1.983722 \n",
      "[8,    10] loss: 1.954 Test Error: Accuracy: 18.9%, Avg loss: 1.942782 \n",
      "[9,    10] loss: 1.943 Test Error: Accuracy: 19.4%, Avg loss: 1.953031 \n",
      "[10,    10] loss: 1.933 Test Error: Accuracy: 20.6%, Avg loss: 1.951477 \n",
      "[11,    10] loss: 1.925 Test Error: Accuracy: 18.3%, Avg loss: 1.952074 \n",
      "[12,    10] loss: 1.913 Test Error: Accuracy: 20.6%, Avg loss: 1.947404 \n",
      "[13,    10] loss: 1.914 Test Error: Accuracy: 21.1%, Avg loss: 1.935630 \n",
      "[14,    10] loss: 1.899 Test Error: Accuracy: 21.1%, Avg loss: 1.943151 \n",
      "[15,    10] loss: 1.909 Test Error: Accuracy: 24.0%, Avg loss: 1.945639 \n",
      "[16,    10] loss: 1.894 Test Error: Accuracy: 23.4%, Avg loss: 1.938486 \n",
      "[17,    10] loss: 1.894 Test Error: Accuracy: 22.3%, Avg loss: 1.924789 \n",
      "[18,    10] loss: 1.892 Test Error: Accuracy: 24.0%, Avg loss: 1.933108 \n",
      "[19,    10] loss: 1.885 Test Error: Accuracy: 24.6%, Avg loss: 1.937658 \n",
      "[20,    10] loss: 1.885 Test Error: Accuracy: 25.1%, Avg loss: 1.917111 \n",
      "[21,    10] loss: 1.880 Test Error: Accuracy: 22.9%, Avg loss: 1.934995 \n",
      "[22,    10] loss: 1.876 Test Error: Accuracy: 23.4%, Avg loss: 1.928958 \n",
      "[23,    10] loss: 1.864 Test Error: Accuracy: 22.3%, Avg loss: 1.925256 \n",
      "[24,    10] loss: 1.858 Test Error: Accuracy: 21.1%, Avg loss: 1.925823 \n",
      "[25,    10] loss: 1.862 Test Error: Accuracy: 22.9%, Avg loss: 1.919789 \n",
      "[26,    10] loss: 1.852 Test Error: Accuracy: 22.9%, Avg loss: 1.919318 \n",
      "[27,    10] loss: 1.853 Test Error: Accuracy: 22.3%, Avg loss: 1.913036 \n",
      "[28,    10] loss: 1.846 Test Error: Accuracy: 17.7%, Avg loss: 1.932980 \n",
      "[29,    10] loss: 1.854 Test Error: Accuracy: 19.4%, Avg loss: 1.923998 \n",
      "[30,    10] loss: 1.839 Test Error: Accuracy: 18.3%, Avg loss: 1.932223 \n",
      "[31,    10] loss: 1.841 Test Error: Accuracy: 16.6%, Avg loss: 1.921565 \n",
      "[32,    10] loss: 1.832 Test Error: Accuracy: 19.4%, Avg loss: 1.926089 \n",
      "[33,    10] loss: 1.824 Test Error: Accuracy: 18.9%, Avg loss: 1.914663 \n",
      "[34,    10] loss: 1.813 Test Error: Accuracy: 24.6%, Avg loss: 1.917213 \n",
      "[35,    10] loss: 1.818 Test Error: Accuracy: 20.0%, Avg loss: 1.918974 \n",
      "[36,    10] loss: 1.807 Test Error: Accuracy: 18.9%, Avg loss: 1.928119 \n",
      "[37,    10] loss: 1.802 Test Error: Accuracy: 24.0%, Avg loss: 1.916213 \n",
      "[38,    10] loss: 1.796 Test Error: Accuracy: 20.6%, Avg loss: 1.919686 \n",
      "[39,    10] loss: 1.801 Test Error: Accuracy: 20.0%, Avg loss: 1.928573 \n",
      "[40,    10] loss: 1.791 Test Error: Accuracy: 21.7%, Avg loss: 1.924590 \n",
      "[41,    10] loss: 1.780 Test Error: Accuracy: 19.4%, Avg loss: 1.933793 \n",
      "[42,    10] loss: 1.776 Test Error: Accuracy: 18.3%, Avg loss: 1.928811 \n",
      "[43,    10] loss: 1.769 Test Error: Accuracy: 22.3%, Avg loss: 1.919491 \n",
      "[44,    10] loss: 1.768 Test Error: Accuracy: 19.4%, Avg loss: 1.932489 \n",
      "[45,    10] loss: 1.754 Test Error: Accuracy: 23.4%, Avg loss: 1.923860 \n",
      "[46,    10] loss: 1.759 Test Error: Accuracy: 18.3%, Avg loss: 1.934087 \n",
      "[47,    10] loss: 1.748 Test Error: Accuracy: 18.9%, Avg loss: 1.929763 \n",
      "[48,    10] loss: 1.771 Test Error: Accuracy: 24.0%, Avg loss: 1.909767 \n",
      "[49,    10] loss: 1.756 Test Error: Accuracy: 16.0%, Avg loss: 1.948420 \n",
      "[50,    10] loss: 1.747 tensor([[8.3579e-03, 6.9073e-01, 1.1495e-01, 1.3260e-05, 1.7891e-01, 7.0151e-03,\n",
      "         3.3513e-05],\n",
      "        [2.1470e-01, 4.8540e-02, 8.4939e-02, 5.0200e-05, 5.8431e-01, 6.7379e-02,\n",
      "         8.7120e-05],\n",
      "        [5.4952e-01, 3.1138e-01, 2.0282e-05, 3.4661e-06, 1.7372e-02, 1.2169e-01,\n",
      "         1.0497e-05],\n",
      "        [4.3783e-04, 9.6456e-03, 9.2400e-01, 1.4211e-06, 6.5917e-02, 2.3523e-07,\n",
      "         1.5829e-06],\n",
      "        [7.6382e-03, 2.5298e-02, 2.6043e-04, 5.8794e-06, 6.5808e-02, 9.0097e-01,\n",
      "         1.7502e-05],\n",
      "        [4.1789e-02, 3.2935e-02, 4.6915e-04, 2.8999e-05, 1.0592e-03, 9.2368e-01,\n",
      "         3.9695e-05],\n",
      "        [3.7285e-03, 8.0290e-02, 3.6210e-03, 1.4094e-05, 1.3232e-01, 7.7998e-01,\n",
      "         3.9273e-05],\n",
      "        [1.2915e-01, 7.6958e-02, 5.5755e-01, 1.5696e-05, 2.3386e-01, 2.4271e-03,\n",
      "         3.2231e-05],\n",
      "        [8.7831e-02, 8.0239e-01, 1.2111e-02, 7.9363e-05, 3.5736e-03, 9.3913e-02,\n",
      "         1.0116e-04]], device='cuda:0', grad_fn=<SliceBackward>) tensor([1, 4, 0, 2, 5, 5, 6, 0, 1], device='cuda:0')\n",
      "Test Error: Accuracy: 21.1%, Avg loss: 1.926822 \n",
      "[51,    10] loss: 1.733 Test Error: Accuracy: 20.0%, Avg loss: 1.921633 \n",
      "[52,    10] loss: 1.730 Test Error: Accuracy: 18.9%, Avg loss: 1.924528 \n",
      "[53,    10] loss: 1.717 Test Error: Accuracy: 16.6%, Avg loss: 1.949085 \n",
      "[54,    10] loss: 1.730 Test Error: Accuracy: 20.0%, Avg loss: 1.924883 \n",
      "[55,    10] loss: 1.718 Test Error: Accuracy: 16.6%, Avg loss: 1.951070 \n",
      "[56,    10] loss: 1.715 Test Error: Accuracy: 21.1%, Avg loss: 1.934397 \n",
      "[57,    10] loss: 1.704 Test Error: Accuracy: 24.0%, Avg loss: 1.907898 \n",
      "[58,    10] loss: 1.710 Test Error: Accuracy: 15.4%, Avg loss: 1.950296 \n",
      "[59,    10] loss: 1.712 Test Error: Accuracy: 17.7%, Avg loss: 1.944535 \n",
      "[60,    10] loss: 1.692 Test Error: Accuracy: 20.0%, Avg loss: 1.937772 \n",
      "[61,    10] loss: 1.690 Test Error: Accuracy: 16.0%, Avg loss: 1.949390 \n",
      "[62,    10] loss: 1.692 Test Error: Accuracy: 19.4%, Avg loss: 1.947557 \n",
      "[63,    10] loss: 1.686 Test Error: Accuracy: 20.6%, Avg loss: 1.939345 \n",
      "[64,    10] loss: 1.688 Test Error: Accuracy: 21.1%, Avg loss: 1.932951 \n",
      "[65,    10] loss: 1.676 Test Error: Accuracy: 20.0%, Avg loss: 1.940133 \n",
      "[66,    10] loss: 1.677 Test Error: Accuracy: 17.1%, Avg loss: 1.942378 \n",
      "[67,    10] loss: 1.667 Test Error: Accuracy: 17.7%, Avg loss: 1.938275 \n",
      "[68,    10] loss: 1.657 Test Error: Accuracy: 15.4%, Avg loss: 1.985816 \n",
      "[69,    10] loss: 1.675 Test Error: Accuracy: 21.1%, Avg loss: 1.935144 \n",
      "[70,    10] loss: 1.661 Test Error: Accuracy: 21.1%, Avg loss: 1.937860 \n",
      "[71,    10] loss: 1.669 Test Error: Accuracy: 20.0%, Avg loss: 1.924531 \n",
      "[72,    10] loss: 1.654 Test Error: Accuracy: 18.9%, Avg loss: 1.945678 \n",
      "[73,    10] loss: 1.642 Test Error: Accuracy: 14.9%, Avg loss: 1.954013 \n",
      "[74,    10] loss: 1.649 Test Error: Accuracy: 21.7%, Avg loss: 1.931408 \n",
      "[75,    10] loss: 1.661 Test Error: Accuracy: 21.1%, Avg loss: 1.917151 \n",
      "[76,    10] loss: 1.638 Test Error: Accuracy: 20.6%, Avg loss: 1.920567 \n",
      "[77,    10] loss: 1.657 Test Error: Accuracy: 21.1%, Avg loss: 1.923660 \n",
      "[78,    10] loss: 1.644 Test Error: Accuracy: 21.1%, Avg loss: 1.918916 \n",
      "[79,    10] loss: 1.637 Test Error: Accuracy: 22.3%, Avg loss: 1.923258 \n",
      "[80,    10] loss: 1.629 Test Error: Accuracy: 23.4%, Avg loss: 1.928777 \n",
      "[81,    10] loss: 1.628 Test Error: Accuracy: 17.1%, Avg loss: 1.954731 \n",
      "[82,    10] loss: 1.625 Test Error: Accuracy: 16.6%, Avg loss: 1.951699 \n",
      "[83,    10] loss: 1.623 Test Error: Accuracy: 18.3%, Avg loss: 1.946233 \n",
      "[84,    10] loss: 1.616 Test Error: Accuracy: 19.4%, Avg loss: 1.931850 \n",
      "[85,    10] loss: 1.620 Test Error: Accuracy: 21.7%, Avg loss: 1.936088 \n",
      "[86,    10] loss: 1.632 Test Error: Accuracy: 17.1%, Avg loss: 1.948143 \n",
      "[87,    10] loss: 1.625 Test Error: Accuracy: 18.3%, Avg loss: 1.953444 \n",
      "[88,    10] loss: 1.613 Test Error: Accuracy: 20.6%, Avg loss: 1.918542 \n",
      "[89,    10] loss: 1.620 Test Error: Accuracy: 18.3%, Avg loss: 1.947371 \n",
      "[90,    10] loss: 1.611 Test Error: Accuracy: 18.9%, Avg loss: 1.928554 \n",
      "[91,    10] loss: 1.598 Test Error: Accuracy: 17.7%, Avg loss: 1.940034 \n",
      "[92,    10] loss: 1.606 Test Error: Accuracy: 16.6%, Avg loss: 1.946944 \n",
      "[93,    10] loss: 1.598 Test Error: Accuracy: 21.7%, Avg loss: 1.925665 \n",
      "[94,    10] loss: 1.600 Test Error: Accuracy: 20.6%, Avg loss: 1.922544 \n",
      "[95,    10] loss: 1.596 Test Error: Accuracy: 21.7%, Avg loss: 1.920500 \n",
      "[96,    10] loss: 1.597 Test Error: Accuracy: 20.6%, Avg loss: 1.932862 \n",
      "[97,    10] loss: 1.596 Test Error: Accuracy: 19.4%, Avg loss: 1.930140 \n",
      "[98,    10] loss: 1.594 Test Error: Accuracy: 17.1%, Avg loss: 1.943239 \n",
      "[99,    10] loss: 1.581 Test Error: Accuracy: 18.3%, Avg loss: 1.937772 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100,    10] loss: 1.576 tensor([[9.1458e-06, 1.8421e-02, 1.5132e-02, 1.2200e-11, 9.6644e-01, 1.0098e-12,\n",
      "         3.4642e-11],\n",
      "        [6.6740e-02, 9.3309e-01, 1.4292e-09, 5.0781e-11, 1.1336e-05, 1.6190e-04,\n",
      "         2.4068e-10],\n",
      "        [9.0358e-01, 1.1132e-02, 3.2951e-03, 1.5069e-09, 8.1989e-02, 2.0075e-08,\n",
      "         3.1330e-09],\n",
      "        [3.2766e-03, 9.8167e-01, 1.0804e-02, 6.8199e-09, 4.2356e-03, 1.4432e-05,\n",
      "         1.9114e-08],\n",
      "        [9.4472e-02, 5.7165e-03, 1.3441e-04, 6.9186e-08, 2.2225e-03, 8.9745e-01,\n",
      "         1.7302e-07],\n",
      "        [1.6738e-06, 6.0815e-04, 6.5129e-03, 7.1681e-12, 9.9288e-01, 9.0954e-13,\n",
      "         1.2584e-11],\n",
      "        [1.1036e-01, 6.6182e-01, 1.1691e-01, 1.6713e-07, 1.0861e-01, 2.2977e-03,\n",
      "         5.0152e-07],\n",
      "        [2.8161e-03, 9.9214e-01, 3.0476e-03, 1.3218e-07, 1.9580e-03, 3.5832e-05,\n",
      "         1.4739e-07],\n",
      "        [1.3667e-06, 3.1910e-02, 9.6589e-01, 3.6079e-10, 2.1960e-03, 1.1032e-12,\n",
      "         3.7804e-10]], device='cuda:0', grad_fn=<SliceBackward>) tensor([4, 1, 3, 1, 3, 4, 1, 1, 2], device='cuda:0')\n",
      "Test Error: Accuracy: 20.0%, Avg loss: 1.926277 \n",
      "[101,    10] loss: 1.581 Test Error: Accuracy: 20.6%, Avg loss: 1.915234 \n",
      "[102,    10] loss: 1.578 Test Error: Accuracy: 19.4%, Avg loss: 1.937202 \n",
      "[103,    10] loss: 1.574 Test Error: Accuracy: 17.7%, Avg loss: 1.927168 \n",
      "[104,    10] loss: 1.569 Test Error: Accuracy: 18.9%, Avg loss: 1.932977 \n",
      "[105,    10] loss: 1.568 Test Error: Accuracy: 15.4%, Avg loss: 1.951825 \n",
      "[106,    10] loss: 1.570 Test Error: Accuracy: 18.3%, Avg loss: 1.941943 \n",
      "[107,    10] loss: 1.558 Test Error: Accuracy: 17.1%, Avg loss: 1.935171 \n",
      "[108,    10] loss: 1.558 Test Error: Accuracy: 20.0%, Avg loss: 1.928688 \n",
      "[109,    10] loss: 1.569 Test Error: Accuracy: 20.0%, Avg loss: 1.919526 \n",
      "[110,    10] loss: 1.571 Test Error: Accuracy: 18.9%, Avg loss: 1.932932 \n",
      "[111,    10] loss: 1.577 Test Error: Accuracy: 18.3%, Avg loss: 1.925298 \n",
      "[112,    10] loss: 1.565 Test Error: Accuracy: 20.0%, Avg loss: 1.927076 \n",
      "[113,    10] loss: 1.549 Test Error: Accuracy: 18.3%, Avg loss: 1.923555 \n",
      "[114,    10] loss: 1.561 Test Error: Accuracy: 18.9%, Avg loss: 1.910013 \n",
      "[115,    10] loss: 1.549 Test Error: Accuracy: 20.0%, Avg loss: 1.921246 \n",
      "[116,    10] loss: 1.556 Test Error: Accuracy: 19.4%, Avg loss: 1.941124 \n",
      "[117,    10] loss: 1.562 Test Error: Accuracy: 19.4%, Avg loss: 1.929421 \n",
      "[118,    10] loss: 1.547 Test Error: Accuracy: 21.1%, Avg loss: 1.922831 \n",
      "[119,    10] loss: 1.561 Test Error: Accuracy: 20.6%, Avg loss: 1.925144 \n",
      "[120,    10] loss: 1.561 Test Error: Accuracy: 20.6%, Avg loss: 1.926273 \n",
      "[121,    10] loss: 1.552 Test Error: Accuracy: 21.1%, Avg loss: 1.910792 \n",
      "[122,    10] loss: 1.559 Test Error: Accuracy: 20.6%, Avg loss: 1.917781 \n",
      "[123,    10] loss: 1.554 Test Error: Accuracy: 20.6%, Avg loss: 1.916337 \n",
      "[124,    10] loss: 1.550 Test Error: Accuracy: 20.6%, Avg loss: 1.926629 \n",
      "[125,    10] loss: 1.547 Test Error: Accuracy: 20.6%, Avg loss: 1.916965 \n",
      "[126,    10] loss: 1.550 Test Error: Accuracy: 22.9%, Avg loss: 1.889444 \n",
      "[127,    10] loss: 1.546 Test Error: Accuracy: 21.1%, Avg loss: 1.891950 \n",
      "[128,    10] loss: 1.547 Test Error: Accuracy: 20.0%, Avg loss: 1.916419 \n",
      "[129,    10] loss: 1.537 Test Error: Accuracy: 20.6%, Avg loss: 1.916374 \n",
      "[130,    10] loss: 1.553 Test Error: Accuracy: 19.4%, Avg loss: 1.926165 \n",
      "[131,    10] loss: 1.538 Test Error: Accuracy: 19.4%, Avg loss: 1.924670 \n",
      "[132,    10] loss: 1.543 Test Error: Accuracy: 22.3%, Avg loss: 1.905023 \n",
      "[133,    10] loss: 1.528 Test Error: Accuracy: 21.1%, Avg loss: 1.917134 \n",
      "[134,    10] loss: 1.532 Test Error: Accuracy: 20.0%, Avg loss: 1.922463 \n",
      "[135,    10] loss: 1.534 Test Error: Accuracy: 21.7%, Avg loss: 1.915689 \n",
      "[136,    10] loss: 1.531 Test Error: Accuracy: 21.7%, Avg loss: 1.911975 \n",
      "[137,    10] loss: 1.536 Test Error: Accuracy: 20.0%, Avg loss: 1.919688 \n",
      "[138,    10] loss: 1.526 Test Error: Accuracy: 22.3%, Avg loss: 1.910303 \n",
      "[139,    10] loss: 1.537 Test Error: Accuracy: 21.1%, Avg loss: 1.909581 \n",
      "[140,    10] loss: 1.518 Test Error: Accuracy: 21.7%, Avg loss: 1.892330 \n",
      "[141,    10] loss: 1.527 Test Error: Accuracy: 18.9%, Avg loss: 1.916309 \n",
      "[142,    10] loss: 1.537 Test Error: Accuracy: 18.9%, Avg loss: 1.939546 \n",
      "[143,    10] loss: 1.533 Test Error: Accuracy: 20.6%, Avg loss: 1.902332 \n",
      "[144,    10] loss: 1.524 Test Error: Accuracy: 20.6%, Avg loss: 1.905556 \n",
      "[145,    10] loss: 1.530 Test Error: Accuracy: 20.6%, Avg loss: 1.913116 \n",
      "[146,    10] loss: 1.531 Test Error: Accuracy: 20.0%, Avg loss: 1.941233 \n",
      "[147,    10] loss: 1.518 Test Error: Accuracy: 21.1%, Avg loss: 1.916988 \n",
      "[148,    10] loss: 1.522 Test Error: Accuracy: 22.3%, Avg loss: 1.918714 \n",
      "[149,    10] loss: 1.516 Test Error: Accuracy: 19.4%, Avg loss: 1.922217 \n",
      "[150,    10] loss: 1.526 tensor([[9.9485e-01, 5.1436e-03, 9.0571e-26, 4.3185e-19, 4.0483e-15, 2.3990e-06,\n",
      "         3.5292e-18],\n",
      "        [6.4132e-07, 1.3513e-03, 9.9386e-01, 4.0611e-14, 4.7899e-03, 1.5560e-16,\n",
      "         7.2314e-14],\n",
      "        [6.6995e-03, 1.5587e-02, 9.0591e-05, 1.3746e-07, 3.2290e-03, 9.7439e-01,\n",
      "         1.7169e-07],\n",
      "        [2.1698e-05, 9.5555e-01, 1.0416e-02, 5.7607e-11, 3.3695e-02, 3.1278e-04,\n",
      "         2.4338e-10],\n",
      "        [1.4083e-03, 1.8753e-03, 5.2574e-03, 1.5161e-13, 9.9146e-01, 3.1293e-14,\n",
      "         3.3787e-13],\n",
      "        [8.0852e-03, 9.7499e-01, 1.6094e-04, 1.0197e-07, 9.6230e-03, 7.1378e-03,\n",
      "         1.1622e-07],\n",
      "        [1.1243e-04, 3.8136e-01, 3.0343e-01, 1.0939e-09, 1.7283e-01, 1.4226e-01,\n",
      "         7.7739e-09],\n",
      "        [1.1634e-04, 8.1160e-03, 9.9082e-01, 3.8913e-14, 9.4456e-04, 1.6646e-15,\n",
      "         9.0678e-14],\n",
      "        [2.2385e-04, 9.9607e-01, 3.1064e-05, 1.6559e-08, 2.6944e-03, 9.7886e-04,\n",
      "         1.9593e-08]], device='cuda:0', grad_fn=<SliceBackward>) tensor([0, 2, 5, 1, 4, 1, 6, 2, 1], device='cuda:0')\n",
      "Test Error: Accuracy: 23.4%, Avg loss: 1.897212 \n",
      "[151,    10] loss: 1.518 Test Error: Accuracy: 21.1%, Avg loss: 1.902596 \n",
      "[152,    10] loss: 1.512 Test Error: Accuracy: 23.4%, Avg loss: 1.904604 \n",
      "[153,    10] loss: 1.509 Test Error: Accuracy: 23.4%, Avg loss: 1.894198 \n",
      "[154,    10] loss: 1.523 Test Error: Accuracy: 21.7%, Avg loss: 1.897443 \n",
      "[155,    10] loss: 1.512 Test Error: Accuracy: 20.6%, Avg loss: 1.930228 \n",
      "[156,    10] loss: 1.505 Test Error: Accuracy: 20.6%, Avg loss: 1.917861 \n",
      "[157,    10] loss: 1.509 Test Error: Accuracy: 22.9%, Avg loss: 1.905670 \n",
      "[158,    10] loss: 1.510 Test Error: Accuracy: 21.1%, Avg loss: 1.913627 \n",
      "[159,    10] loss: 1.513 Test Error: Accuracy: 22.9%, Avg loss: 1.885064 \n",
      "[160,    10] loss: 1.517 Test Error: Accuracy: 22.9%, Avg loss: 1.883403 \n",
      "[161,    10] loss: 1.506 Test Error: Accuracy: 23.4%, Avg loss: 1.904087 \n",
      "[162,    10] loss: 1.517 Test Error: Accuracy: 25.7%, Avg loss: 1.893308 \n",
      "[163,    10] loss: 1.502 Test Error: Accuracy: 21.7%, Avg loss: 1.906118 \n",
      "[164,    10] loss: 1.505 Test Error: Accuracy: 20.6%, Avg loss: 1.921374 \n",
      "[165,    10] loss: 1.499 Test Error: Accuracy: 23.4%, Avg loss: 1.906096 \n",
      "[166,    10] loss: 1.512 Test Error: Accuracy: 21.7%, Avg loss: 1.906438 \n",
      "[167,    10] loss: 1.509 Test Error: Accuracy: 22.3%, Avg loss: 1.918844 \n",
      "[168,    10] loss: 1.505 Test Error: Accuracy: 26.3%, Avg loss: 1.893418 \n",
      "[169,    10] loss: 1.504 Test Error: Accuracy: 24.6%, Avg loss: 1.894427 \n",
      "[170,    10] loss: 1.500 Test Error: Accuracy: 25.1%, Avg loss: 1.886598 \n",
      "[171,    10] loss: 1.506 Test Error: Accuracy: 25.1%, Avg loss: 1.902485 \n",
      "[172,    10] loss: 1.507 Test Error: Accuracy: 24.6%, Avg loss: 1.886746 \n",
      "[173,    10] loss: 1.496 Test Error: Accuracy: 22.3%, Avg loss: 1.894806 \n",
      "[174,    10] loss: 1.496 Test Error: Accuracy: 24.6%, Avg loss: 1.887379 \n",
      "[175,    10] loss: 1.494 Test Error: Accuracy: 22.9%, Avg loss: 1.895407 \n",
      "[176,    10] loss: 1.492 Test Error: Accuracy: 24.0%, Avg loss: 1.899323 \n",
      "[177,    10] loss: 1.502 Test Error: Accuracy: 24.6%, Avg loss: 1.893037 \n",
      "[178,    10] loss: 1.507 Test Error: Accuracy: 28.0%, Avg loss: 1.862393 \n",
      "[179,    10] loss: 1.510 Test Error: Accuracy: 24.0%, Avg loss: 1.893161 \n",
      "[180,    10] loss: 1.492 Test Error: Accuracy: 21.7%, Avg loss: 1.878213 \n",
      "[181,    10] loss: 1.507 Test Error: Accuracy: 25.7%, Avg loss: 1.884578 \n",
      "[182,    10] loss: 1.502 Test Error: Accuracy: 26.3%, Avg loss: 1.876018 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183,    10] loss: 1.480 Test Error: Accuracy: 24.6%, Avg loss: 1.872709 \n",
      "[184,    10] loss: 1.494 Test Error: Accuracy: 27.4%, Avg loss: 1.860237 \n",
      "[185,    10] loss: 1.489 Test Error: Accuracy: 25.7%, Avg loss: 1.864703 \n",
      "[186,    10] loss: 1.490 Test Error: Accuracy: 25.1%, Avg loss: 1.880505 \n",
      "[187,    10] loss: 1.500 Test Error: Accuracy: 26.3%, Avg loss: 1.883410 \n",
      "[188,    10] loss: 1.495 Test Error: Accuracy: 28.0%, Avg loss: 1.857654 \n",
      "[189,    10] loss: 1.503 Test Error: Accuracy: 24.6%, Avg loss: 1.875712 \n",
      "[190,    10] loss: 1.495 Test Error: Accuracy: 25.1%, Avg loss: 1.876424 \n",
      "[191,    10] loss: 1.495 Test Error: Accuracy: 26.3%, Avg loss: 1.899812 \n",
      "[192,    10] loss: 1.495 Test Error: Accuracy: 24.6%, Avg loss: 1.895396 \n",
      "[193,    10] loss: 1.499 Test Error: Accuracy: 26.9%, Avg loss: 1.865127 \n",
      "[194,    10] loss: 1.497 Test Error: Accuracy: 26.3%, Avg loss: 1.845285 \n",
      "[195,    10] loss: 1.485 Test Error: Accuracy: 26.3%, Avg loss: 1.865416 \n",
      "[196,    10] loss: 1.499 Test Error: Accuracy: 29.1%, Avg loss: 1.873976 \n",
      "[197,    10] loss: 1.490 Test Error: Accuracy: 26.9%, Avg loss: 1.867278 \n",
      "[198,    10] loss: 1.501 Test Error: Accuracy: 27.4%, Avg loss: 1.861433 \n",
      "[199,    10] loss: 1.489 Test Error: Accuracy: 24.6%, Avg loss: 1.893990 \n",
      "[200,    10] loss: 1.503 tensor([[4.6796e-09, 8.3618e-04, 9.9870e-01, 8.6976e-19, 4.6024e-04, 2.9094e-20,\n",
      "         4.5517e-18],\n",
      "        [4.2460e-08, 9.9991e-01, 6.8685e-05, 1.1339e-17, 1.7764e-05, 1.4509e-15,\n",
      "         6.9712e-17],\n",
      "        [5.6251e-04, 8.3172e-03, 9.8761e-01, 7.1196e-10, 3.5061e-03, 7.6277e-07,\n",
      "         7.3845e-10],\n",
      "        [4.0370e-03, 7.4669e-02, 9.3066e-05, 5.5339e-12, 3.0649e-02, 8.9055e-01,\n",
      "         5.8853e-11],\n",
      "        [1.6030e-04, 1.3119e-05, 3.5426e-02, 1.1144e-11, 9.6440e-01, 1.7536e-10,\n",
      "         1.2048e-11],\n",
      "        [7.3544e-07, 9.9997e-01, 2.4193e-05, 2.5890e-18, 5.2734e-06, 2.3681e-23,\n",
      "         4.5098e-18],\n",
      "        [6.6094e-01, 1.4838e-02, 2.8727e-03, 4.9087e-10, 3.2085e-01, 5.0277e-04,\n",
      "         1.3057e-09],\n",
      "        [4.5049e-06, 9.9999e-01, 8.7997e-17, 9.5773e-18, 1.0467e-07, 3.0385e-07,\n",
      "         8.8622e-17],\n",
      "        [3.1645e-03, 2.9855e-03, 2.4564e-03, 2.4393e-11, 1.7780e-04, 9.9122e-01,\n",
      "         1.3562e-10]], device='cuda:0', grad_fn=<SliceBackward>) tensor([2, 1, 2, 5, 4, 1, 3, 1, 5], device='cuda:0')\n",
      "Test Error: Accuracy: 25.7%, Avg loss: 1.878137 \n",
      "[201,    10] loss: 1.495 Test Error: Accuracy: 26.9%, Avg loss: 1.891840 \n",
      "[202,    10] loss: 1.491 Test Error: Accuracy: 27.4%, Avg loss: 1.875170 \n",
      "[203,    10] loss: 1.492 Test Error: Accuracy: 26.3%, Avg loss: 1.879948 \n",
      "[204,    10] loss: 1.494 Test Error: Accuracy: 25.1%, Avg loss: 1.892076 \n",
      "[205,    10] loss: 1.496 Test Error: Accuracy: 25.7%, Avg loss: 1.865832 \n",
      "[206,    10] loss: 1.489 Test Error: Accuracy: 27.4%, Avg loss: 1.891112 \n",
      "[207,    10] loss: 1.487 Test Error: Accuracy: 26.9%, Avg loss: 1.869580 \n",
      "[208,    10] loss: 1.498 Test Error: Accuracy: 26.3%, Avg loss: 1.867911 \n",
      "[209,    10] loss: 1.492 Test Error: Accuracy: 28.0%, Avg loss: 1.863619 \n",
      "[210,    10] loss: 1.488 Test Error: Accuracy: 25.7%, Avg loss: 1.882635 \n",
      "[211,    10] loss: 1.486 Test Error: Accuracy: 28.0%, Avg loss: 1.884322 \n",
      "[212,    10] loss: 1.491 Test Error: Accuracy: 25.7%, Avg loss: 1.863186 \n",
      "[213,    10] loss: 1.485 Test Error: Accuracy: 26.9%, Avg loss: 1.869466 \n",
      "[214,    10] loss: 1.481 Test Error: Accuracy: 27.4%, Avg loss: 1.869483 \n",
      "[215,    10] loss: 1.495 Test Error: Accuracy: 26.9%, Avg loss: 1.868528 \n",
      "[216,    10] loss: 1.494 Test Error: Accuracy: 28.0%, Avg loss: 1.867313 \n",
      "[217,    10] loss: 1.493 Test Error: Accuracy: 28.0%, Avg loss: 1.870581 \n",
      "[218,    10] loss: 1.486 Test Error: Accuracy: 26.9%, Avg loss: 1.865467 \n",
      "[219,    10] loss: 1.483 Test Error: Accuracy: 26.9%, Avg loss: 1.865128 \n",
      "[220,    10] loss: 1.487 Test Error: Accuracy: 28.6%, Avg loss: 1.852113 \n",
      "[221,    10] loss: 1.486 Test Error: Accuracy: 28.6%, Avg loss: 1.855001 \n",
      "[222,    10] loss: 1.478 Test Error: Accuracy: 29.1%, Avg loss: 1.864763 \n",
      "[223,    10] loss: 1.481 Test Error: Accuracy: 29.7%, Avg loss: 1.858498 \n",
      "[224,    10] loss: 1.486 Test Error: Accuracy: 28.6%, Avg loss: 1.870081 \n",
      "[225,    10] loss: 1.485 Test Error: Accuracy: 30.3%, Avg loss: 1.844560 \n",
      "[226,    10] loss: 1.478 Test Error: Accuracy: 27.4%, Avg loss: 1.872727 \n",
      "[227,    10] loss: 1.486 Test Error: Accuracy: 31.4%, Avg loss: 1.847790 \n",
      "[228,    10] loss: 1.487 Test Error: Accuracy: 28.6%, Avg loss: 1.846641 \n",
      "[229,    10] loss: 1.487 Test Error: Accuracy: 28.0%, Avg loss: 1.846359 \n",
      "[230,    10] loss: 1.487 Test Error: Accuracy: 28.6%, Avg loss: 1.852575 \n",
      "[231,    10] loss: 1.489 Test Error: Accuracy: 30.3%, Avg loss: 1.857247 \n",
      "[232,    10] loss: 1.489 Test Error: Accuracy: 29.7%, Avg loss: 1.849479 \n",
      "[233,    10] loss: 1.476 Test Error: Accuracy: 28.6%, Avg loss: 1.863055 \n",
      "[234,    10] loss: 1.491 Test Error: Accuracy: 30.3%, Avg loss: 1.843673 \n",
      "[235,    10] loss: 1.486 Test Error: Accuracy: 30.3%, Avg loss: 1.837891 \n",
      "[236,    10] loss: 1.488 Test Error: Accuracy: 29.1%, Avg loss: 1.861589 \n",
      "[237,    10] loss: 1.485 Test Error: Accuracy: 32.0%, Avg loss: 1.831446 \n",
      "[238,    10] loss: 1.490 Test Error: Accuracy: 31.4%, Avg loss: 1.847528 \n",
      "[239,    10] loss: 1.484 Test Error: Accuracy: 31.4%, Avg loss: 1.854564 \n",
      "[240,    10] loss: 1.484 Test Error: Accuracy: 31.4%, Avg loss: 1.864125 \n",
      "[241,    10] loss: 1.494 Test Error: Accuracy: 32.6%, Avg loss: 1.849923 \n",
      "[242,    10] loss: 1.481 Test Error: Accuracy: 29.7%, Avg loss: 1.856268 \n",
      "[243,    10] loss: 1.483 Test Error: Accuracy: 30.9%, Avg loss: 1.843976 \n",
      "[244,    10] loss: 1.484 Test Error: Accuracy: 29.7%, Avg loss: 1.855641 \n",
      "[245,    10] loss: 1.480 Test Error: Accuracy: 28.0%, Avg loss: 1.850898 \n",
      "[246,    10] loss: 1.487 Test Error: Accuracy: 29.7%, Avg loss: 1.853042 \n",
      "[247,    10] loss: 1.483 Test Error: Accuracy: 30.3%, Avg loss: 1.847500 \n",
      "[248,    10] loss: 1.479 Test Error: Accuracy: 30.3%, Avg loss: 1.860350 \n",
      "[249,    10] loss: 1.490 Test Error: Accuracy: 31.4%, Avg loss: 1.841375 \n",
      "[250,    10] loss: 1.480 tensor([[4.3760e-03, 9.9460e-01, 4.5932e-04, 1.9722e-09, 5.0383e-04, 5.7657e-05,\n",
      "         2.0580e-09],\n",
      "        [9.9932e-01, 1.5197e-05, 1.3510e-11, 1.4162e-17, 6.6333e-04, 3.1664e-13,\n",
      "         4.5048e-17],\n",
      "        [2.5191e-06, 3.8232e-06, 9.9965e-01, 1.7248e-12, 3.4845e-04, 2.6301e-09,\n",
      "         1.6853e-12],\n",
      "        [9.9977e-01, 1.2463e-04, 1.1606e-25, 1.4545e-21, 8.8116e-13, 1.0190e-04,\n",
      "         1.5436e-20],\n",
      "        [4.4883e-06, 1.8764e-03, 9.1531e-03, 2.5732e-13, 1.0789e-02, 9.7818e-01,\n",
      "         2.6144e-12],\n",
      "        [9.9990e-01, 2.4054e-06, 7.4637e-06, 1.4134e-12, 8.0127e-12, 9.0520e-05,\n",
      "         1.6948e-12],\n",
      "        [9.9548e-01, 3.4068e-03, 6.6965e-06, 5.3611e-11, 1.1030e-03, 4.4204e-06,\n",
      "         5.1337e-11],\n",
      "        [4.6518e-05, 9.6038e-04, 3.0315e-06, 3.5309e-13, 4.2159e-04, 9.9857e-01,\n",
      "         1.3380e-12],\n",
      "        [9.8175e-01, 1.4988e-02, 4.2521e-05, 4.0235e-09, 9.7610e-04, 2.2402e-03,\n",
      "         4.5038e-09]], device='cuda:0', grad_fn=<SliceBackward>) tensor([1, 0, 2, 0, 5, 0, 0, 5, 0], device='cuda:0')\n",
      "Test Error: Accuracy: 30.3%, Avg loss: 1.846668 \n",
      "[251,    10] loss: 1.479 Test Error: Accuracy: 29.7%, Avg loss: 1.858677 \n",
      "[252,    10] loss: 1.488 Test Error: Accuracy: 29.7%, Avg loss: 1.845840 \n",
      "[253,    10] loss: 1.484 Test Error: Accuracy: 28.6%, Avg loss: 1.875055 \n",
      "[254,    10] loss: 1.485 Test Error: Accuracy: 31.4%, Avg loss: 1.845603 \n",
      "[255,    10] loss: 1.485 Test Error: Accuracy: 30.9%, Avg loss: 1.866648 \n",
      "[256,    10] loss: 1.481 Test Error: Accuracy: 29.7%, Avg loss: 1.842449 \n",
      "[257,    10] loss: 1.477 Test Error: Accuracy: 29.1%, Avg loss: 1.856895 \n",
      "[258,    10] loss: 1.487 Test Error: Accuracy: 31.4%, Avg loss: 1.856070 \n",
      "[259,    10] loss: 1.474 Test Error: Accuracy: 29.7%, Avg loss: 1.843735 \n",
      "[260,    10] loss: 1.483 Test Error: Accuracy: 29.7%, Avg loss: 1.883165 \n",
      "[261,    10] loss: 1.489 Test Error: Accuracy: 30.3%, Avg loss: 1.847386 \n",
      "[262,    10] loss: 1.484 Test Error: Accuracy: 30.9%, Avg loss: 1.836208 \n",
      "[263,    10] loss: 1.477 Test Error: Accuracy: 30.9%, Avg loss: 1.856088 \n",
      "[264,    10] loss: 1.479 Test Error: Accuracy: 30.3%, Avg loss: 1.850563 \n",
      "[265,    10] loss: 1.481 Test Error: Accuracy: 30.3%, Avg loss: 1.838825 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266,    10] loss: 1.472 Test Error: Accuracy: 32.6%, Avg loss: 1.843355 \n",
      "[267,    10] loss: 1.482 Test Error: Accuracy: 32.6%, Avg loss: 1.863431 \n",
      "[268,    10] loss: 1.482 Test Error: Accuracy: 30.3%, Avg loss: 1.851011 \n",
      "[269,    10] loss: 1.488 Test Error: Accuracy: 29.1%, Avg loss: 1.842695 \n",
      "[270,    10] loss: 1.483 Test Error: Accuracy: 32.0%, Avg loss: 1.852490 \n",
      "[271,    10] loss: 1.481 Test Error: Accuracy: 30.3%, Avg loss: 1.872345 \n",
      "[272,    10] loss: 1.482 Test Error: Accuracy: 29.7%, Avg loss: 1.853761 \n",
      "[273,    10] loss: 1.478 Test Error: Accuracy: 30.3%, Avg loss: 1.835184 \n",
      "[274,    10] loss: 1.472 Test Error: Accuracy: 31.4%, Avg loss: 1.853136 \n",
      "[275,    10] loss: 1.489 Test Error: Accuracy: 29.1%, Avg loss: 1.849606 \n",
      "[276,    10] loss: 1.472 Test Error: Accuracy: 30.3%, Avg loss: 1.851895 \n",
      "[277,    10] loss: 1.491 Test Error: Accuracy: 28.0%, Avg loss: 1.861298 \n",
      "[278,    10] loss: 1.483 Test Error: Accuracy: 26.3%, Avg loss: 1.902525 \n",
      "[279,    10] loss: 1.495 Test Error: Accuracy: 27.4%, Avg loss: 1.877801 \n",
      "[280,    10] loss: 1.491 Test Error: Accuracy: 26.3%, Avg loss: 1.865174 \n",
      "[281,    10] loss: 1.490 Test Error: Accuracy: 31.4%, Avg loss: 1.853869 \n",
      "[282,    10] loss: 1.490 Test Error: Accuracy: 32.6%, Avg loss: 1.844423 \n",
      "[283,    10] loss: 1.479 Test Error: Accuracy: 29.7%, Avg loss: 1.864550 \n",
      "[284,    10] loss: 1.478 Test Error: Accuracy: 29.7%, Avg loss: 1.847395 \n",
      "[285,    10] loss: 1.489 Test Error: Accuracy: 28.0%, Avg loss: 1.861615 \n",
      "[286,    10] loss: 1.480 Test Error: Accuracy: 29.1%, Avg loss: 1.844990 \n",
      "[287,    10] loss: 1.484 Test Error: Accuracy: 32.6%, Avg loss: 1.846163 \n",
      "[288,    10] loss: 1.478 Test Error: Accuracy: 26.3%, Avg loss: 1.879527 \n",
      "[289,    10] loss: 1.468 Test Error: Accuracy: 30.3%, Avg loss: 1.851676 \n",
      "[290,    10] loss: 1.472 Test Error: Accuracy: 28.0%, Avg loss: 1.882708 \n",
      "[291,    10] loss: 1.479 Test Error: Accuracy: 28.0%, Avg loss: 1.856451 \n",
      "[292,    10] loss: 1.483 Test Error: Accuracy: 31.4%, Avg loss: 1.843411 \n",
      "[293,    10] loss: 1.486 Test Error: Accuracy: 29.1%, Avg loss: 1.860618 \n",
      "[294,    10] loss: 1.481 Test Error: Accuracy: 31.4%, Avg loss: 1.856433 \n",
      "[295,    10] loss: 1.481 Test Error: Accuracy: 32.0%, Avg loss: 1.827214 \n",
      "[296,    10] loss: 1.462 Test Error: Accuracy: 33.7%, Avg loss: 1.853898 \n",
      "[297,    10] loss: 1.468 Test Error: Accuracy: 30.9%, Avg loss: 1.850629 \n",
      "[298,    10] loss: 1.468 Test Error: Accuracy: 31.4%, Avg loss: 1.847556 \n",
      "[299,    10] loss: 1.469 Test Error: Accuracy: 29.7%, Avg loss: 1.861656 \n",
      "[300,    10] loss: 1.478 tensor([[1.0278e-01, 7.9343e-01, 1.7727e-03, 2.7005e-09, 8.9972e-04, 1.0112e-01,\n",
      "         5.2509e-09],\n",
      "        [4.3124e-08, 1.0000e+00, 2.6848e-06, 3.6348e-20, 1.7548e-09, 6.2309e-18,\n",
      "         1.5887e-19],\n",
      "        [1.3328e-06, 1.0000e+00, 2.3245e-06, 6.1250e-13, 2.5197e-07, 1.4075e-08,\n",
      "         5.5956e-13],\n",
      "        [1.4259e-02, 5.7419e-04, 9.8559e-04, 4.0361e-09, 3.6389e-03, 9.8054e-01,\n",
      "         6.1566e-09],\n",
      "        [7.0061e-02, 4.2149e-02, 3.3429e-03, 2.6922e-12, 7.1242e-01, 1.7203e-01,\n",
      "         2.9122e-11],\n",
      "        [2.9614e-03, 5.2738e-04, 4.4913e-07, 1.9868e-14, 1.1202e-03, 9.9539e-01,\n",
      "         3.2305e-13],\n",
      "        [2.6572e-07, 1.1224e-06, 9.9947e-01, 5.8793e-17, 5.3325e-04, 3.7439e-19,\n",
      "         5.1005e-17],\n",
      "        [9.2553e-03, 1.6771e-03, 4.9997e-03, 4.3874e-12, 9.8406e-01, 3.3181e-06,\n",
      "         1.0657e-11],\n",
      "        [2.2124e-02, 2.8975e-01, 4.1775e-01, 1.7713e-19, 2.7037e-01, 6.9653e-22,\n",
      "         1.0577e-18]], device='cuda:0', grad_fn=<SliceBackward>) tensor([6, 1, 1, 5, 6, 5, 2, 3, 3], device='cuda:0')\n",
      "Test Error: Accuracy: 31.4%, Avg loss: 1.838435 \n",
      "[301,    10] loss: 1.462 Test Error: Accuracy: 30.3%, Avg loss: 1.840131 \n",
      "[302,    10] loss: 1.476 Test Error: Accuracy: 27.4%, Avg loss: 1.872760 \n",
      "[303,    10] loss: 1.466 Test Error: Accuracy: 26.3%, Avg loss: 1.895974 \n",
      "[304,    10] loss: 1.474 Test Error: Accuracy: 29.7%, Avg loss: 1.856585 \n",
      "[305,    10] loss: 1.477 Test Error: Accuracy: 32.0%, Avg loss: 1.831800 \n",
      "[306,    10] loss: 1.472 Test Error: Accuracy: 31.4%, Avg loss: 1.845890 \n",
      "[307,    10] loss: 1.478 Test Error: Accuracy: 28.6%, Avg loss: 1.862437 \n",
      "[308,    10] loss: 1.481 Test Error: Accuracy: 28.0%, Avg loss: 1.858417 \n",
      "[309,    10] loss: 1.479 Test Error: Accuracy: 30.9%, Avg loss: 1.851559 \n",
      "[310,    10] loss: 1.469 Test Error: Accuracy: 29.7%, Avg loss: 1.871067 \n",
      "[311,    10] loss: 1.472 Test Error: Accuracy: 30.9%, Avg loss: 1.844335 \n",
      "[312,    10] loss: 1.476 Test Error: Accuracy: 28.6%, Avg loss: 1.867304 \n",
      "[313,    10] loss: 1.470 Test Error: Accuracy: 28.6%, Avg loss: 1.889267 \n",
      "[314,    10] loss: 1.466 Test Error: Accuracy: 27.4%, Avg loss: 1.870293 \n",
      "[315,    10] loss: 1.472 Test Error: Accuracy: 29.7%, Avg loss: 1.849453 \n",
      "[316,    10] loss: 1.481 Test Error: Accuracy: 30.3%, Avg loss: 1.854686 \n",
      "[317,    10] loss: 1.469 Test Error: Accuracy: 31.4%, Avg loss: 1.866809 \n",
      "[318,    10] loss: 1.478 Test Error: Accuracy: 28.0%, Avg loss: 1.846997 \n",
      "[319,    10] loss: 1.469 Test Error: Accuracy: 30.9%, Avg loss: 1.844884 \n",
      "[320,    10] loss: 1.457 Test Error: Accuracy: 29.7%, Avg loss: 1.879215 \n",
      "[321,    10] loss: 1.472 Test Error: Accuracy: 29.1%, Avg loss: 1.864113 \n",
      "[322,    10] loss: 1.483 Test Error: Accuracy: 30.3%, Avg loss: 1.870013 \n",
      "[323,    10] loss: 1.462 Test Error: Accuracy: 28.0%, Avg loss: 1.871485 \n",
      "[324,    10] loss: 1.471 Test Error: Accuracy: 29.7%, Avg loss: 1.871510 \n",
      "[325,    10] loss: 1.470 Test Error: Accuracy: 31.4%, Avg loss: 1.858250 \n",
      "[326,    10] loss: 1.476 Test Error: Accuracy: 28.6%, Avg loss: 1.849047 \n",
      "[327,    10] loss: 1.464 Test Error: Accuracy: 29.1%, Avg loss: 1.844906 \n",
      "[328,    10] loss: 1.459 Test Error: Accuracy: 27.4%, Avg loss: 1.882906 \n",
      "[329,    10] loss: 1.466 Test Error: Accuracy: 28.6%, Avg loss: 1.887239 \n",
      "[330,    10] loss: 1.462 Test Error: Accuracy: 30.3%, Avg loss: 1.859080 \n",
      "[331,    10] loss: 1.474 Test Error: Accuracy: 29.7%, Avg loss: 1.856302 \n",
      "[332,    10] loss: 1.471 Test Error: Accuracy: 29.1%, Avg loss: 1.856593 \n",
      "[333,    10] loss: 1.461 Test Error: Accuracy: 30.9%, Avg loss: 1.867478 \n",
      "[334,    10] loss: 1.461 Test Error: Accuracy: 28.6%, Avg loss: 1.852849 \n",
      "[335,    10] loss: 1.474 Test Error: Accuracy: 28.6%, Avg loss: 1.860745 \n",
      "[336,    10] loss: 1.474 Test Error: Accuracy: 29.1%, Avg loss: 1.868870 \n",
      "[337,    10] loss: 1.467 Test Error: Accuracy: 27.4%, Avg loss: 1.867623 \n",
      "[338,    10] loss: 1.475 Test Error: Accuracy: 30.9%, Avg loss: 1.847820 \n",
      "[339,    10] loss: 1.466 Test Error: Accuracy: 28.6%, Avg loss: 1.852861 \n",
      "[340,    10] loss: 1.466 Test Error: Accuracy: 28.6%, Avg loss: 1.831584 \n",
      "[341,    10] loss: 1.473 Test Error: Accuracy: 29.7%, Avg loss: 1.833923 \n",
      "[342,    10] loss: 1.464 Test Error: Accuracy: 28.6%, Avg loss: 1.868818 \n",
      "[343,    10] loss: 1.468 Test Error: Accuracy: 31.4%, Avg loss: 1.846897 \n",
      "[344,    10] loss: 1.469 Test Error: Accuracy: 28.0%, Avg loss: 1.849358 \n",
      "[345,    10] loss: 1.472 Test Error: Accuracy: 28.6%, Avg loss: 1.855237 \n",
      "[346,    10] loss: 1.458 Test Error: Accuracy: 26.9%, Avg loss: 1.866105 \n",
      "[347,    10] loss: 1.467 Test Error: Accuracy: 27.4%, Avg loss: 1.872941 \n",
      "[348,    10] loss: 1.474 Test Error: Accuracy: 28.0%, Avg loss: 1.869402 \n",
      "[349,    10] loss: 1.462 Test Error: Accuracy: 30.9%, Avg loss: 1.863150 \n",
      "[350,    10] loss: 1.459 tensor([[3.8842e-05, 4.7261e-07, 1.0676e-04, 2.8428e-18, 9.9985e-01, 1.2246e-14,\n",
      "         7.7850e-18],\n",
      "        [1.6693e-06, 9.9699e-01, 7.5709e-04, 4.3370e-15, 2.1920e-03, 5.7354e-05,\n",
      "         3.2808e-14],\n",
      "        [1.9273e-04, 8.7456e-04, 2.3288e-05, 6.6165e-12, 4.1913e-05, 9.9887e-01,\n",
      "         2.0822e-11],\n",
      "        [1.0309e-01, 3.5981e-02, 5.3087e-04, 6.1697e-08, 8.9951e-03, 8.5141e-01,\n",
      "         8.4831e-08],\n",
      "        [9.9641e-01, 1.6941e-03, 4.3939e-05, 5.2930e-10, 1.3428e-03, 5.0730e-04,\n",
      "         7.9476e-10],\n",
      "        [9.9794e-01, 1.5214e-03, 7.4528e-06, 6.7969e-11, 4.4763e-04, 7.9193e-05,\n",
      "         1.2808e-10],\n",
      "        [3.1726e-08, 2.6753e-06, 5.2134e-04, 1.0689e-15, 9.9948e-01, 5.0670e-15,\n",
      "         1.5083e-15],\n",
      "        [1.4339e-08, 1.2146e-04, 9.9839e-01, 7.1166e-17, 1.4921e-03, 1.3974e-12,\n",
      "         3.6817e-16],\n",
      "        [2.4458e-01, 4.1850e-01, 1.0924e-04, 1.1447e-08, 5.4401e-02, 2.8241e-01,\n",
      "         1.4992e-08]], device='cuda:0', grad_fn=<SliceBackward>) tensor([4, 1, 5, 6, 0, 0, 4, 2, 6], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: Accuracy: 30.3%, Avg loss: 1.853639 \n",
      "[351,    10] loss: 1.469 Test Error: Accuracy: 28.6%, Avg loss: 1.859889 \n",
      "[352,    10] loss: 1.458 Test Error: Accuracy: 28.0%, Avg loss: 1.863470 \n",
      "[353,    10] loss: 1.476 Test Error: Accuracy: 28.6%, Avg loss: 1.857377 \n",
      "[354,    10] loss: 1.462 Test Error: Accuracy: 30.3%, Avg loss: 1.870883 \n",
      "[355,    10] loss: 1.463 Test Error: Accuracy: 29.7%, Avg loss: 1.858239 \n",
      "[356,    10] loss: 1.469 Test Error: Accuracy: 28.6%, Avg loss: 1.874659 \n",
      "[357,    10] loss: 1.460 Test Error: Accuracy: 28.6%, Avg loss: 1.864140 \n",
      "[358,    10] loss: 1.466 Test Error: Accuracy: 30.3%, Avg loss: 1.839069 \n",
      "[359,    10] loss: 1.465 Test Error: Accuracy: 28.6%, Avg loss: 1.868205 \n",
      "[360,    10] loss: 1.458 Test Error: Accuracy: 29.7%, Avg loss: 1.844937 \n",
      "[361,    10] loss: 1.465 Test Error: Accuracy: 29.1%, Avg loss: 1.868947 \n",
      "[362,    10] loss: 1.461 Test Error: Accuracy: 29.1%, Avg loss: 1.865953 \n",
      "[363,    10] loss: 1.467 Test Error: Accuracy: 28.6%, Avg loss: 1.851608 \n",
      "[364,    10] loss: 1.462 Test Error: Accuracy: 30.9%, Avg loss: 1.865045 \n",
      "[365,    10] loss: 1.469 Test Error: Accuracy: 29.7%, Avg loss: 1.866815 \n",
      "[366,    10] loss: 1.471 Test Error: Accuracy: 30.9%, Avg loss: 1.864935 \n",
      "[367,    10] loss: 1.464 Test Error: Accuracy: 30.9%, Avg loss: 1.858402 \n",
      "[368,    10] loss: 1.453 Test Error: Accuracy: 30.3%, Avg loss: 1.860101 \n",
      "[369,    10] loss: 1.460 Test Error: Accuracy: 30.9%, Avg loss: 1.874864 \n",
      "[370,    10] loss: 1.464 Test Error: Accuracy: 30.9%, Avg loss: 1.855255 \n",
      "[371,    10] loss: 1.467 Test Error: Accuracy: 29.7%, Avg loss: 1.870184 \n",
      "[372,    10] loss: 1.463 Test Error: Accuracy: 31.4%, Avg loss: 1.851115 \n",
      "[373,    10] loss: 1.464 Test Error: Accuracy: 29.7%, Avg loss: 1.861189 \n",
      "[374,    10] loss: 1.465 Test Error: Accuracy: 30.3%, Avg loss: 1.851625 \n",
      "[375,    10] loss: 1.467 Test Error: Accuracy: 30.3%, Avg loss: 1.877039 \n",
      "[376,    10] loss: 1.464 Test Error: Accuracy: 30.3%, Avg loss: 1.859002 \n",
      "[377,    10] loss: 1.456 Test Error: Accuracy: 29.1%, Avg loss: 1.872145 \n",
      "[378,    10] loss: 1.462 Test Error: Accuracy: 29.1%, Avg loss: 1.866974 \n",
      "[379,    10] loss: 1.463 "
     ]
    }
   ],
   "source": [
    "for epoch in range(500):  # loop over the dataset multiple times\n",
    "    train(train_dataloader, optimizer, criterion, model)\n",
    "    test(test_dataloader, optimizer, criterion, model)\n",
    "print('Finished Training')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
