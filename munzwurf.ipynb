{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_cache = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Search for all h5 files\n",
    "        p = Path(file_path)\n",
    "        files = p.glob('*.h5')\n",
    "        for h5dataset_fp in files:\n",
    "            with h5py.File(h5dataset_fp.resolve()) as h5_file:\n",
    "                # Walk through all groups, extracting datasets\n",
    "                for gname, group in h5_file.items():\n",
    "                    if gname == 'oneCent':\n",
    "                        label = 1\n",
    "                    elif gname == 'twoCent':\n",
    "                        label = 2\n",
    "                    elif gname == 'fiveCent':\n",
    "                        label = 5\n",
    "                    elif gname == 'twentyCent':\n",
    "                        label = 20\n",
    "                    elif gname == 'fiftyCent':\n",
    "                        label = 50\n",
    "                    elif gname == 'oneEuro':\n",
    "                        label = 100\n",
    "                    elif gname == 'twoEuro':\n",
    "                        label = 200\n",
    "                    for dname, ds in group.items():\n",
    "                        self.data_cache.append([label, torch.tensor(ds[:760000], dtype=torch.float32).unsqueeze(0)])\n",
    "                        #self.data_cache.append([label, torch.tensor((1, ds[:760000]))])\n",
    "                        \n",
    "            print(self.data_cache[0][1].size())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_cache[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 760000])\n"
     ]
    }
   ],
   "source": [
    "file_dir = \"/home/marcus/Documents/munzwurf/data_normalized\"\n",
    "labels_dir = \"/home/marcus/Documents/munzwurf/data/labels.csv\"\n",
    "\n",
    "customData = CustomDataset(\"/home/marcus/PycharmProjects/pythonProject/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, tensor([[ 224.,   64.,  -96.,  ..., -576., -160.,   96.]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(customData)\n",
    "customData[212]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.array(np.floor(np.random.rand(100) * 1000), dtype=int)\n",
    "#tested a bunch of random indices to get a balanced representation of labels\n",
    "tested_indices = [ 75, 296, 705, 917, 596, 117, 987, 681, 746, 189, 868, 661, 752, 462, 362, 322,  50,  90,\n",
    " 526,  53, 15, 403, 881, 226, 428, 453,  80, 312, 486, 690, 842, 959, 247, 224, 748, 772,\n",
    " 620, 617, 108,  96, 212, 649, 866, 707, 956, 772, 234, 339, 166, 954, 602, 935, 707, 717,\n",
    "  14, 672, 891, 415, 199, 511,   2, 998, 628, 651,  47, 115, 966,  29,   5, 240, 371,  85,\n",
    "  18, 997,  68, 170, 325, 807, 378, 566, 763, 121,   3, 442, 674, 938, 393, 763, 755, 336,\n",
    " 419, 408, 104, 923, 580, 530, 859, 371, 957, 535]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array([], dtype=int)\n",
    "test_labels = [i[0] for i in customData[::20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Subset(customData, tested_indices)\n",
    "test_data = Subset(CustomDataset, np.arange(800, len(customData)))\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=False, num_workers=4)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=4, shuffle=True, pin_memory=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_count = []\n",
    "for i in [1,2,5,20,50,100,200]:\n",
    "    label_count.append(np.count_nonzero(test_labels == i))\n",
    "\n",
    "plt.bar(range(7), label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 2, kernel_size=3, padding=1) \n",
    "        self.conv2 = nn.Conv1d(2, 4, kernel_size=3, padding=1) \n",
    "        self.conv3 = nn.Conv1d(4, 8, kernel_size=3, padding=1) \n",
    "        self.conv4 = nn.Conv1d(8, 16, kernel_size=3, padding=1) \n",
    "        self.conv5 = nn.Conv1d(16, 32, kernel_size=3, padding=1) \n",
    "      \n",
    "        self.fc1   = nn.Linear(101248, 7)  #262500\n",
    "     \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv3(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv4(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool1d(F.relu(self.conv5(x)),3)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1) \n",
    "        print(x.shape)\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "        \"\"\"\n",
    "        Size after each layer\n",
    "        torch.Size([64, 1, 262500])\n",
    "        torch.Size([64, 1, 131250])\n",
    "        torch.Size([64, 1, 65625])\n",
    "        torch.Size([64, 1, 32812])\n",
    "        torch.Size([64, 1, 16406])\n",
    "        \"\"\"\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv1d(1, 2, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv2): Conv1d(2, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(4, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv4): Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv5): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=101248, out_features=7, bias=True)\n",
      ")\n",
      "710851\n"
     ]
    }
   ],
   "source": [
    "model = Network().to(device)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs tensor([[-1600., -2624., -1408.,  ...,  -352.,    32.,    64.]]) labels tensor(100)\n",
      "torch.Size([64, 100064])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x100064 and 101248x7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5743/1399596148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5743/3169338156.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[1;32m     30\u001b[0m         \u001b[0mSize\u001b[0m \u001b[0mafter\u001b[0m \u001b[0meach\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x100064 and 101248x7)"
     ]
    }
   ],
   "source": [
    "loss_array = []\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    j = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        \n",
    "        inputs = data[1]#.unsqueeze(1)\n",
    "        labels = data[0]\n",
    "        print(\"inputs\", inputs[0], \"labels\", labels[1])\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #loss_array.append(loss.item())\n",
    "        #loss_plot = plt.plot(range(len(loss_array)), loss_array)\n",
    "        #plt.show()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(loss)\n",
    "        if i % 5 == 4:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            print(outputs, labels)\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
